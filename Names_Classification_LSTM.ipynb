{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12MYXv9aNSo3ZUyfEQtnoVXf-SNwbEe5b",
      "authorship_tag": "ABX9TyNUsDxirgdrjd98jtf+ghLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taaha3244/NLP-a-day-keeps-doctors-away/blob/main/Names_Classification_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/data.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxLLMnyKSxJ1",
        "outputId": "c72a7fde-022b-4cb5-d4c7-05828f358908"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP_RA31OOkDS",
        "outputId": "2cd5d2df-5eb2-4dff-a7f3-766b36072d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20074 [('Adamidis', 'Greek'), ('Adamou', 'Greek'), ('Agelakos', 'Greek'), ('Akrivopoulos', 'Greek'), ('Alexandropoulos', 'Greek')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Load all names from the files in the 'names' folder and include their nationality\n",
        "Path = '/content/data/names/'\n",
        "file_names = os.listdir(Path)\n",
        "all_names = []\n",
        "nationalities = []\n",
        "for filename in file_names:\n",
        "    nationality = os.path.splitext(filename)[0]  # Nationality is the file name without extension\n",
        "    with open(Path + filename, 'r', encoding='utf-8') as file:\n",
        "        names = file.read().splitlines()\n",
        "        all_names.extend(names)\n",
        "        nationalities.extend([nationality] * len(names))  # Extend with the nationality for each name\n",
        "\n",
        "# Example: Checking the total number of names and the first few names with their nationalities\n",
        "total_names = len(all_names)\n",
        "sample_data = list(zip(all_names[:5], nationalities[:5]))  # Pairing names with nationalities\n",
        "print(total_names, sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_char_mapping(names):\n",
        "    # Identify unique characters\n",
        "    unique_chars = set(''.join(names))\n",
        "    # Create a mapping from characters to integers\n",
        "    char_to_int = {char: i for i, char in enumerate(unique_chars, 1)}  # Starting from 1 for zero-indexing\n",
        "    return char_to_int\n",
        "\n",
        "# Apply the function to your dataset\n",
        "char_to_int = create_char_mapping(all_names)\n",
        "\n",
        "# Example: Display the character-to-integer mapping\n",
        "print(char_to_int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwGfvn_bTOfh",
        "outputId": "4ce2cef8-2702-4eb9-e7ed-953f6b1a69ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ń': 1, 'ö': 2, 'k': 3, 'ß': 4, 'ê': 5, 'õ': 6, 's': 7, 'C': 8, 'ú': 9, 'ì': 10, 'G': 11, 'F': 12, 'ł': 13, 'i': 14, 'y': 15, 'ü': 16, 'I': 17, 'à': 18, 'H': 19, 'd': 20, 'ó': 21, 'w': 22, 'm': 23, 'q': 24, 'ç': 25, 'W': 26, 'f': 27, 'U': 28, 'ã': 29, 'A': 30, ':': 31, 'a': 32, 'ż': 33, 'R': 34, 'M': 35, '1': 36, 'l': 37, 'h': 38, 'g': 39, 'í': 40, 'Á': 41, 'u': 42, 'N': 43, 'T': 44, 'J': 45, 'S': 46, 'Y': 47, 'x': 48, 'D': 49, 'X': 50, 'V': 51, 'ä': 52, 'è': 53, 'O': 54, 'j': 55, \"'\": 56, 'Z': 57, 'P': 58, ',': 59, 'á': 60, 'Q': 61, 'o': 62, 'z': 63, 'r': 64, 'L': 65, 'ò': 66, 't': 67, 'Ś': 68, 'Ż': 69, 'e': 70, 'É': 71, 'é': 72, 'b': 73, 'c': 74, '/': 75, 'n': 76, ' ': 77, 'E': 78, 'ą': 79, 'B': 80, 'v': 81, '-': 82, 'K': 83, 'p': 84, '\\xa0': 85, 'ñ': 86, 'ù': 87}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nationality_mapping(nationalities):\n",
        "    # Identify unique nationalities\n",
        "    unique_nationalities = set(nationalities)\n",
        "    # Create a mapping from nationalities to integers\n",
        "    nationality_to_int = {nationality: i for i, nationality in enumerate(unique_nationalities)}\n",
        "    return nationality_to_int\n",
        "\n",
        "# Apply the function to your list of nationalities\n",
        "nationality_to_int = create_nationality_mapping(nationalities)\n",
        "\n",
        "# Example: Display the nationality-to-integer mapping\n",
        "print(nationality_to_int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfBcZWOdZ0cB",
        "outputId": "445141ea-a73f-4bbb-80cf-0b43be65a261"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'German': 0, 'French': 1, 'Czech': 2, 'Korean': 3, 'Italian': 4, 'Chinese': 5, 'Scottish': 6, 'Irish': 7, 'Greek': 8, 'Russian': 9, 'Polish': 10, 'Arabic': 11, 'English': 12, 'Japanese': 13, 'Spanish': 14, 'Vietnamese': 15, 'Portuguese': 16, 'Dutch': 17}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Function to encode the names and nationalities\n",
        "def encode_data(names, nationalities, char_to_int, nationality_to_int):\n",
        "    # Encode names\n",
        "    encoded_names = [[char_to_int[char] for char in name] for name in names]\n",
        "    # Encode nationalities\n",
        "    encoded_nationalities = [nationality_to_int[nationality] for nationality in nationalities]\n",
        "    return encoded_names, encoded_nationalities\n",
        "\n",
        "# Applying the encoding function\n",
        "encoded_names, encoded_nationalities = encode_data(all_names, nationalities, char_to_int, nationality_to_int)\n",
        "\n",
        "# Padding sequences to have the same length\n",
        "max_name_length = max([len(name) for name in encoded_names])\n",
        "X = pad_sequences(encoded_names, maxlen=max_name_length, padding='post')\n",
        "\n",
        "# Converting labels to numpy array for use with PyTorch\n",
        "y = np.array(encoded_nationalities)\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verifying the shape of the processed data\n",
        "X_train.shape, X_val.shape, len(y_train), len(y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBtamQJXO7xp",
        "outputId": "9ef99d39-1496-45c2-b547-f0d3090e696d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16059, 20), (4015, 20), 16059, 4015)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = NameDataset(X_train, y_train)\n",
        "val_dataset = NameDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "s6S0wJ4EPWGp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, num_chars, embedding_dim, hidden_dim, num_classes):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_chars, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "# Instantiate the model with hidden dimensions\n",
        "num_chars=len(char_to_int)+1\n",
        "hidden_dim = 128  # This is a hyperparameter you can tune\n",
        "num_classes = len(nationality_to_int)\n",
        "model = LSTMClassifier(num_chars, embedding_dim=64, hidden_dim=hidden_dim, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "q3_CXVOaPqmn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tINeXYmeQzCS",
        "outputId": "e0392e96-5a3a-4e86-95cc-cc3535c64a31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Checking if GPU is available and moving the model to GPU if it is\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYKM-k6zR0PS",
        "outputId": "bd0fddf1-3dbd-4906-a831-6d783080f689"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embedding): Embedding(88, 64)\n",
              "  (lstm): LSTM(64, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform a training epoch\n",
        "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Function to perform a validation epoch\n",
        "def validate_epoch(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Number of epochs can be adjusted\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = validate_epoch(model, val_loader, criterion, device)\n",
        "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0Ntw7zR46Y",
        "outputId": "10ab085f-3279-41e9-d69e-afb3d847a385"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.8514, Val Loss: 1.5622\n",
            "Epoch 2: Train Loss: 1.4266, Val Loss: 1.3001\n",
            "Epoch 3: Train Loss: 1.1393, Val Loss: 0.9955\n",
            "Epoch 4: Train Loss: 0.9040, Val Loss: 0.8153\n",
            "Epoch 5: Train Loss: 0.7607, Val Loss: 0.7639\n",
            "Epoch 6: Train Loss: 0.6628, Val Loss: 0.6879\n",
            "Epoch 7: Train Loss: 0.5997, Val Loss: 0.7001\n",
            "Epoch 8: Train Loss: 0.5422, Val Loss: 0.6479\n",
            "Epoch 9: Train Loss: 0.4978, Val Loss: 0.6379\n",
            "Epoch 10: Train Loss: 0.4617, Val Loss: 0.6166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.nograd():\n",
        "  output=model"
      ],
      "metadata": {
        "id": "Tbzqnf-qR8TA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}